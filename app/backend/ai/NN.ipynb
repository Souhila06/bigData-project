{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset\n",
    "df = pd.read_csv('./final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/0tnfv35j1jjbznbfc7k0swh00000gn/T/ipykernel_15434/178802134.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sample = df.groupby('activityID', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Nombre de classes\n",
    "n_classes = df['activityID'].nunique()\n",
    "n_classes = 25\n",
    "n_total = 3000000\n",
    "\n",
    "# Taille de l'échantillon par classe\n",
    "n_per_class = n_total // n_classes\n",
    "\n",
    "# Échantillonnage uniforme\n",
    "sample = df.groupby('activityID', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(len(x), n_per_class), random_state=42)\n",
    ")\n",
    "\n",
    "# Réinitialiser les indices\n",
    "sample = sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activityID\n",
       "0     120000\n",
       "7     120000\n",
       "19    120000\n",
       "17    120000\n",
       "16    120000\n",
       "1     120000\n",
       "10    120000\n",
       "6     120000\n",
       "4     120000\n",
       "3     120000\n",
       "2     120000\n",
       "12    117216\n",
       "13    104944\n",
       "18     99878\n",
       "5      98199\n",
       "9      83646\n",
       "11     54519\n",
       "24     49360\n",
       "20     46915\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['activityID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données\n",
    "X = sample.drop(columns=[\"activityID\", \"timestamp\"])  # Supprimer les colonnes inutiles\n",
    "y = sample[\"activityID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Diviser les données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construction du modèle de réseau de neurones\n",
    "# Création du modèle\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(n_classes, activation='softmax')  # Pour une classification multi-classes\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.6249 - loss: 1.2874 - val_accuracy: 0.8760 - val_loss: 0.3792\n",
      "Epoch 2/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.8299 - loss: 0.5295 - val_accuracy: 0.8983 - val_loss: 0.3012\n",
      "Epoch 3/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.8507 - loss: 0.4659 - val_accuracy: 0.9124 - val_loss: 0.2661\n",
      "Epoch 4/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.8607 - loss: 0.4341 - val_accuracy: 0.9165 - val_loss: 0.2525\n",
      "Epoch 5/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.8676 - loss: 0.4131 - val_accuracy: 0.9194 - val_loss: 0.2408\n",
      "Epoch 6/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.8728 - loss: 0.3985 - val_accuracy: 0.9227 - val_loss: 0.2288\n",
      "Epoch 7/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.8764 - loss: 0.3870 - val_accuracy: 0.9276 - val_loss: 0.2161\n",
      "Epoch 8/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.8800 - loss: 0.3759 - val_accuracy: 0.9305 - val_loss: 0.2081\n",
      "Epoch 9/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.3676 - val_accuracy: 0.9333 - val_loss: 0.1992\n",
      "Epoch 10/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.8856 - loss: 0.3584 - val_accuracy: 0.9345 - val_loss: 0.1969\n",
      "Epoch 11/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.8867 - loss: 0.3531 - val_accuracy: 0.9354 - val_loss: 0.1887\n",
      "Epoch 12/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.8896 - loss: 0.3452 - val_accuracy: 0.9374 - val_loss: 0.1862\n",
      "Epoch 13/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.8908 - loss: 0.3408 - val_accuracy: 0.9375 - val_loss: 0.1883\n",
      "Epoch 14/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.8927 - loss: 0.3358 - val_accuracy: 0.9422 - val_loss: 0.1775\n",
      "Epoch 15/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.8937 - loss: 0.3327 - val_accuracy: 0.9392 - val_loss: 0.1827\n",
      "Epoch 16/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.8950 - loss: 0.3306 - val_accuracy: 0.9402 - val_loss: 0.1777\n",
      "Epoch 17/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.8966 - loss: 0.3262 - val_accuracy: 0.9423 - val_loss: 0.1739\n",
      "Epoch 18/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.8974 - loss: 0.3231 - val_accuracy: 0.9413 - val_loss: 0.1780\n",
      "Epoch 19/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.8979 - loss: 0.3208 - val_accuracy: 0.9432 - val_loss: 0.1688\n",
      "Epoch 20/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.3191 - val_accuracy: 0.9423 - val_loss: 0.1710\n",
      "Epoch 21/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.9002 - loss: 0.3145 - val_accuracy: 0.9450 - val_loss: 0.1672\n",
      "Epoch 22/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.3133 - val_accuracy: 0.9457 - val_loss: 0.1605\n",
      "Epoch 23/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9015 - loss: 0.3095 - val_accuracy: 0.9465 - val_loss: 0.1621\n",
      "Epoch 24/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9020 - loss: 0.3094 - val_accuracy: 0.9439 - val_loss: 0.1689\n",
      "Epoch 25/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.9027 - loss: 0.3064 - val_accuracy: 0.9469 - val_loss: 0.1571\n",
      "Epoch 26/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.3031 - val_accuracy: 0.9477 - val_loss: 0.1626\n",
      "Epoch 27/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.9049 - loss: 0.3013 - val_accuracy: 0.9479 - val_loss: 0.1555\n",
      "Epoch 28/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.3029 - val_accuracy: 0.9465 - val_loss: 0.1592\n",
      "Epoch 29/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9051 - loss: 0.3013 - val_accuracy: 0.9493 - val_loss: 0.1508\n",
      "Epoch 30/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 874us/step - accuracy: 0.9057 - loss: 0.2985 - val_accuracy: 0.9485 - val_loss: 0.1569\n",
      "Epoch 31/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9057 - loss: 0.2980 - val_accuracy: 0.9482 - val_loss: 0.1524\n",
      "Epoch 32/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9070 - loss: 0.2946 - val_accuracy: 0.9486 - val_loss: 0.1550\n",
      "Epoch 33/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2928 - val_accuracy: 0.9482 - val_loss: 0.1553\n",
      "Epoch 34/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.2943 - val_accuracy: 0.9515 - val_loss: 0.1460\n",
      "Epoch 35/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9080 - loss: 0.2927 - val_accuracy: 0.9492 - val_loss: 0.1527\n",
      "Epoch 36/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2903 - val_accuracy: 0.9517 - val_loss: 0.1459\n",
      "Epoch 37/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2887 - val_accuracy: 0.9496 - val_loss: 0.1513\n",
      "Epoch 38/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.9101 - loss: 0.2864 - val_accuracy: 0.9507 - val_loss: 0.1472\n",
      "Epoch 39/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2872 - val_accuracy: 0.9518 - val_loss: 0.1431\n",
      "Epoch 40/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2866 - val_accuracy: 0.9486 - val_loss: 0.1521\n",
      "Epoch 41/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.2860 - val_accuracy: 0.9526 - val_loss: 0.1444\n",
      "Epoch 42/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2870 - val_accuracy: 0.9524 - val_loss: 0.1447\n",
      "Epoch 43/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2863 - val_accuracy: 0.9511 - val_loss: 0.1503\n",
      "Epoch 44/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2842 - val_accuracy: 0.9532 - val_loss: 0.1417\n",
      "Epoch 45/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2814 - val_accuracy: 0.9517 - val_loss: 0.1461\n",
      "Epoch 46/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2829 - val_accuracy: 0.9523 - val_loss: 0.1428\n",
      "Epoch 47/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2825 - val_accuracy: 0.9531 - val_loss: 0.1409\n",
      "Epoch 48/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2826 - val_accuracy: 0.9533 - val_loss: 0.1426\n",
      "Epoch 49/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2787 - val_accuracy: 0.9539 - val_loss: 0.1382\n",
      "Epoch 50/50\n",
      "\u001b[1m9874/9874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2800 - val_accuracy: 0.9536 - val_loss: 0.1394\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12342/12342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 232us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  4 ... 18  6  1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "print(y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.44%\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.61      0.71     23874\n",
      "           1       1.00      0.97      0.99     23903\n",
      "           2       0.99      0.98      0.99     23930\n",
      "           3       0.95      0.99      0.97     24037\n",
      "           4       0.93      0.96      0.94     24105\n",
      "           5       0.99      0.98      0.98     19848\n",
      "           6       0.98      0.99      0.99     24002\n",
      "           7       0.96      0.96      0.96     23981\n",
      "           9       1.00      0.99      1.00     16764\n",
      "          10       1.00      0.99      1.00     23935\n",
      "          11       1.00      1.00      1.00     10945\n",
      "          12       0.89      0.97      0.93     23442\n",
      "          13       0.90      0.96      0.92     21288\n",
      "          16       0.95      0.97      0.96     24069\n",
      "          17       0.96      0.97      0.97     23745\n",
      "          18       0.96      0.98      0.97     19785\n",
      "          19       0.96      0.97      0.97     23970\n",
      "          20       0.95      0.97      0.96      9336\n",
      "          24       0.96      0.99      0.97      9977\n",
      "\n",
      "    accuracy                           0.95    394936\n",
      "   macro avg       0.96      0.96      0.96    394936\n",
      "weighted avg       0.95      0.95      0.95    394936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  9 10 11 12 13 16 17 18 19 20 24]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "[18]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[101.0,34.5625,-5.90031,4.90636,3.1681,-5.81862,5.227,3.44635,0.284144,0.0166734,-0.313876,47.6911,-41.2161,3.94013,1.0,0.0,0.0,0.0,37.3125,-0.104606,-4.0706,-9.433,-0.379479,-4.11858,-8.96098,0.0583489,0.0208029,-0.160818,-10.319,41.947,43.0069,1.0,0.0,0.0,0.0,36.375,9.01379,-3.60497,-2.67982,9.0058,-3.52498,-1.99554,0.0426612,0.0112998,0.055789,-63.2542,-0.971412,3.54882,1.0,0.0,0.0,0.0]])\n",
    "#print(x)\n",
    "y_pred = model.predict(x)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "print(y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.9109217e-05 1.9588556e-15 9.8351038e-23 7.8485727e-20 4.3274556e-27\n",
      "  6.6132307e-32 4.8801242e-32 8.4781839e-33 0.0000000e+00 1.3723647e-18\n",
      "  1.1638954e-15 8.4217193e-16 9.3565036e-26 2.3131121e-22 0.0000000e+00\n",
      "  0.0000000e+00 2.8135275e-17 9.0254820e-10 9.9992085e-01 5.3022415e-08\n",
      "  5.0999043e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model in HDF5 format\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.9109217e-05 1.9588556e-15 9.8351038e-23 7.8485727e-20 4.3274556e-27\n",
      "  6.6132307e-32 4.8801242e-32 8.4781839e-33 0.0000000e+00 1.3723647e-18\n",
      "  1.1638954e-15 8.4217193e-16 9.3565036e-26 2.3131121e-22 0.0000000e+00\n",
      "  0.0000000e+00 2.8135275e-17 9.0254820e-10 9.9992085e-01 5.3022415e-08\n",
      "  5.0999043e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
